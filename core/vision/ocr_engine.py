"""
Module OCR optimis√© pour JARVIS
Combine Tesseract et EasyOCR avec cache intelligent
"""
import asyncio
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from PIL import Image
import pytesseract
import easyocr
import cv2
import numpy as np
from loguru import logger
import hashlib
import json
from pathlib import Path

@dataclass
class OCRResult:
    """R√©sultat d'une reconnaissance OCR"""
    text: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # x, y, width, height
    engine: str  # "tesseract" ou "easyocr"
    language: str = "fr"
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "text": self.text,
            "confidence": self.confidence,
            "bbox": self.bbox,
            "engine": self.engine,
            "language": self.language
        }

@dataclass
class OCRFullResult:
    """R√©sultat complet d'une analyse OCR"""
    all_text: str
    words: List[OCRResult]
    lines: List[str]
    confidence_avg: float
    processing_time: float
    image_hash: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "all_text": self.all_text,
            "words": [word.to_dict() for word in self.words],
            "lines": self.lines,
            "confidence_avg": self.confidence_avg,
            "processing_time": self.processing_time,
            "image_hash": self.image_hash
        }

class OCRCache:
    """Cache intelligent pour les r√©sultats OCR"""
    
    def __init__(self, max_size: int = 100, cache_file: str = "cache/ocr_cache.json"):
        self.max_size = max_size
        self.cache_file = Path(cache_file)
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.access_times: Dict[str, float] = {}
        
        self._load_cache()
    
    def _load_cache(self):
        """Charge le cache depuis le fichier"""
        try:
            if self.cache_file.exists():
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.cache = data.get('cache', {})
                    self.access_times = data.get('access_times', {})
                logger.info(f"üìã Cache OCR charg√©: {len(self.cache)} entr√©es")
        except Exception as e:
            logger.warning(f"Erreur chargement cache OCR: {e}")
            self.cache = {}
            self.access_times = {}
    
    def _save_cache(self):
        """Sauvegarde le cache dans le fichier"""
        try:
            self.cache_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'cache': self.cache,
                    'access_times': self.access_times
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Erreur sauvegarde cache OCR: {e}")
    
    def get(self, image_hash: str) -> Optional[OCRFullResult]:
        """R√©cup√®re un r√©sultat du cache"""
        if image_hash in self.cache:
            self.access_times[image_hash] = time.time()
            data = self.cache[image_hash]
            
            # Reconstituer l'objet OCRFullResult
            words = [OCRResult(**word_data) for word_data in data['words']]
            result = OCRFullResult(
                all_text=data['all_text'],
                words=words,
                lines=data['lines'],
                confidence_avg=data['confidence_avg'],
                processing_time=data['processing_time'],
                image_hash=data['image_hash']
            )
            return result
        return None
    
    def put(self, image_hash: str, result: OCRFullResult):
        """Ajoute un r√©sultat au cache"""
        if len(self.cache) >= self.max_size:
            self._cleanup()
        
        self.cache[image_hash] = result.to_dict()
        self.access_times[image_hash] = time.time()
        
        # Sauvegarde p√©riodique
        if len(self.cache) % 10 == 0:
            self._save_cache()
    
    def _cleanup(self):
        """Nettoie le cache"""
        if not self.access_times:
            return
        
        keep_count = int(self.max_size * 0.8)
        sorted_items = sorted(self.access_times.items(), key=lambda x: x[1], reverse=True)
        
        for key, _ in sorted_items[keep_count:]:
            self.cache.pop(key, None)
            self.access_times.pop(key, None)
    
    def save(self):
        """Force la sauvegarde du cache"""
        self._save_cache()

class TesseractEngine:
    """Moteur Tesseract pour OCR"""
    
    def __init__(self):
        self.config = "--oem 3 --psm 6"  # LSTM OCR Engine + Uniform text block
        self.languages = ['fra', 'eng']  # Fran√ßais + Anglais
        
    def extract_text(self, image: Image.Image, language: str = 'fra+eng') -> OCRFullResult:
        """Extraction de texte avec Tesseract"""
        start_time = time.time()
        
        try:
            # Conversion en numpy array pour preprocessing
            img_array = np.array(image)
            
            # Preprocessing pour am√©liorer la reconnaissance
            img_array = self._preprocess_image(img_array)
            
            # OCR avec donn√©es d√©taill√©es
            data = pytesseract.image_to_data(
                img_array, 
                lang=language, 
                config=self.config, 
                output_type=pytesseract.Output.DICT
            )
            
            # Extraction du texte complet
            all_text = pytesseract.image_to_string(
                img_array, 
                lang=language, 
                config=self.config
            ).strip()
            
            # Traitement des r√©sultats d√©taill√©s
            words = []
            confidences = []
            
            for i in range(len(data['text'])):
                text = data['text'][i].strip()
                if text and int(data['conf'][i]) > 0:
                    bbox = (
                        data['left'][i],
                        data['top'][i],
                        data['width'][i],
                        data['height'][i]
                    )
                    
                    word_result = OCRResult(
                        text=text,
                        confidence=float(data['conf'][i]) / 100.0,
                        bbox=bbox,
                        engine="tesseract",
                        language=language
                    )
                    
                    words.append(word_result)
                    confidences.append(word_result.confidence)
            
            # Lignes de texte
            lines = [line.strip() for line in all_text.split('\n') if line.strip()]
            
            # Confiance moyenne
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            processing_time = time.time() - start_time
            image_hash = hashlib.md5(image.tobytes()).hexdigest()
            
            return OCRFullResult(
                all_text=all_text,
                words=words,
                lines=lines,
                confidence_avg=avg_confidence,
                processing_time=processing_time,
                image_hash=image_hash
            )
            
        except Exception as e:
            logger.error(f"Erreur Tesseract OCR: {e}")
            return OCRFullResult(
                all_text="",
                words=[],
                lines=[],
                confidence_avg=0.0,
                processing_time=time.time() - start_time,
                image_hash=hashlib.md5(image.tobytes()).hexdigest()
            )
    
    def _preprocess_image(self, img_array: np.ndarray) -> np.ndarray:
        """Preprocessing de l'image pour am√©liorer l'OCR"""
        # Conversion en niveaux de gris si n√©cessaire
        if len(img_array.shape) == 3:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # Am√©lioration du contraste
        img_array = cv2.convertScaleAbs(img_array, alpha=1.2, beta=10)
        
        # D√©bruitage
        img_array = cv2.fastNlMeansDenoising(img_array)
        
        # Binarisation adaptative pour am√©liorer la lisibilit√©
        img_array = cv2.adaptiveThreshold(
            img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        return img_array

class EasyOCREngine:
    """Moteur EasyOCR pour OCR"""
    
    def __init__(self):
        self.reader = None
        self.languages = ['fr', 'en']
        
    async def initialize(self):
        """Initialise EasyOCR (peut √™tre lent au premier d√©marrage)"""
        try:
            logger.info("üîÑ Initialisation EasyOCR...")
            self.reader = easyocr.Reader(self.languages, gpu=True)  # Essaie GPU d'abord
            logger.success("‚úÖ EasyOCR initialis√© avec GPU")
        except Exception as e:
            logger.warning(f"GPU non disponible pour EasyOCR, fallback CPU: {e}")
            try:
                self.reader = easyocr.Reader(self.languages, gpu=False)
                logger.success("‚úÖ EasyOCR initialis√© avec CPU")
            except Exception as e2:
                logger.error(f"‚ùå Erreur initialisation EasyOCR: {e2}")
                raise
    
    def extract_text(self, image: Image.Image) -> OCRFullResult:
        """Extraction de texte avec EasyOCR"""
        if not self.reader:
            raise RuntimeError("EasyOCR non initialis√©")
        
        start_time = time.time()
        
        try:
            # Conversion en numpy array
            img_array = np.array(image)
            
            # OCR avec EasyOCR
            results = self.reader.readtext(img_array)
            
            # Traitement des r√©sultats
            words = []
            all_text_parts = []
            confidences = []
            
            for (bbox, text, confidence) in results:
                if text.strip() and confidence > 0.1:  # Seuil de confiance minimum
                    # Conversion bbox EasyOCR vers format standard
                    x_coords = [point[0] for point in bbox]
                    y_coords = [point[1] for point in bbox]
                    
                    x, y = int(min(x_coords)), int(min(y_coords))
                    width = int(max(x_coords) - min(x_coords))
                    height = int(max(y_coords) - min(y_coords))
                    
                    word_result = OCRResult(
                        text=text.strip(),
                        confidence=confidence,
                        bbox=(x, y, width, height),
                        engine="easyocr",
                        language="auto"
                    )
                    
                    words.append(word_result)
                    all_text_parts.append(text.strip())
                    confidences.append(confidence)
            
            # Texte complet
            all_text = ' '.join(all_text_parts)
            
            # Lignes (approximation bas√©e sur la position Y)
            words_sorted = sorted(words, key=lambda w: w.bbox[1])  # Tri par Y
            lines = []
            current_line = []
            last_y = -1
            line_threshold = 20  # Pixels de tol√©rance pour les lignes
            
            for word in words_sorted:
                if last_y == -1 or abs(word.bbox[1] - last_y) <= line_threshold:
                    current_line.append(word.text)
                else:
                    if current_line:
                        lines.append(' '.join(current_line))
                    current_line = [word.text]
                last_y = word.bbox[1]
            
            if current_line:
                lines.append(' '.join(current_line))
            
            # Confiance moyenne
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            processing_time = time.time() - start_time
            image_hash = hashlib.md5(image.tobytes()).hexdigest()
            
            return OCRFullResult(
                all_text=all_text,
                words=words,
                lines=lines,
                confidence_avg=avg_confidence,
                processing_time=processing_time,
                image_hash=image_hash
            )
            
        except Exception as e:
            logger.error(f"Erreur EasyOCR: {e}")
            return OCRFullResult(
                all_text="",
                words=[],
                lines=[],
                confidence_avg=0.0,
                processing_time=time.time() - start_time,
                image_hash=hashlib.md5(image.tobytes()).hexdigest()
            )

class OCREngine:
    """Moteur OCR principal combinant Tesseract et EasyOCR"""
    
    def __init__(self, use_cache: bool = True):
        self.tesseract = TesseractEngine()
        self.easyocr = EasyOCREngine()
        self.cache = OCRCache() if use_cache else None
        self.fallback_engine = "tesseract"  # Moteur de fallback
        
        logger.info("üîç Moteur OCR initialis√©")
    
    async def initialize(self):
        """Initialise tous les moteurs OCR"""
        try:
            # V√©rifier Tesseract
            try:
                pytesseract.get_tesseract_version()
                logger.success("‚úÖ Tesseract disponible")
            except Exception as e:
                logger.error(f"‚ùå Tesseract non disponible: {e}")
                raise
            
            # Initialiser EasyOCR
            await self.easyocr.initialize()
            
            logger.success("‚úÖ Moteur OCR compl√®tement initialis√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation OCR: {e}")
            raise
    
    async def extract_text(self, image: Image.Image, 
                          engine: str = "auto", 
                          use_cache: bool = True) -> OCRFullResult:
        """
        Extraction de texte depuis une image
        
        Args:
            image: Image PIL
            engine: "tesseract", "easyocr", "auto" ou "both"
            use_cache: Utiliser le cache
        """
        # V√©rification du cache
        image_hash = hashlib.md5(image.tobytes()).hexdigest()
        
        if use_cache and self.cache:
            cached_result = self.cache.get(image_hash)
            if cached_result:
                logger.debug("üîç R√©sultat OCR r√©cup√©r√© du cache")
                return cached_result
        
        try:
            result = None
            
            if engine == "tesseract":
                result = self.tesseract.extract_text(image)
            
            elif engine == "easyocr":
                result = self.easyocr.extract_text(image)
            
            elif engine == "both":
                # Utiliser les deux moteurs et combiner
                result = await self._combine_engines(image)
            
            elif engine == "auto":
                # Choix automatique du meilleur moteur
                result = await self._auto_select_engine(image)
            
            else:
                raise ValueError(f"Moteur OCR non reconnu: {engine}")
            
            # Mise en cache
            if result and use_cache and self.cache:
                self.cache.put(image_hash, result)
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction OCR: {e}")
            # Fallback vers le moteur par d√©faut
            if engine != self.fallback_engine:
                logger.info(f"üîÑ Fallback vers {self.fallback_engine}")
                return await self.extract_text(image, self.fallback_engine, use_cache)
            
            # Retourner un r√©sultat vide en cas d'√©chec total
            return OCRFullResult(
                all_text="",
                words=[],
                lines=[],
                confidence_avg=0.0,
                processing_time=0.0,
                image_hash=image_hash
            )
    
    async def _auto_select_engine(self, image: Image.Image) -> OCRFullResult:
        """S√©lection automatique du meilleur moteur bas√©e sur l'analyse de l'image"""
        import cv2
        import numpy as np
        
        # Convertir en array numpy pour analyse
        img_array = np.array(image)
        
        # Analyser les caract√©ristiques de l'image
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
        
        # Calculer des m√©triques
        contrast = np.std(gray)
        brightness = np.mean(gray)
        edge_density = np.mean(cv2.Canny(gray, 50, 150))
        
        # Logique de s√©lection bas√©e sur les caract√©ristiques
        if contrast < 30:
            # Faible contraste - Tesseract avec pr√©traitement
            logger.debug("üîç Image faible contraste - utilisation Tesseract avec pr√©traitement")
            return self.tesseract.extract_text(image)
        elif edge_density > 20:
            # Beaucoup de d√©tails/texte - EasyOCR plus robuste
            logger.debug("üîç Image complexe - utilisation EasyOCR")
            try:
                return self.easyocr.extract_text(image)
            except Exception:
                return self.tesseract.extract_text(image)
        elif brightness > 200:
            # Image tr√®s claire - Tesseract g√©n√©ralement meilleur
            logger.debug("üîç Image claire - utilisation Tesseract")
            return self.tesseract.extract_text(image)
        else:
            # Cas par d√©faut - EasyOCR avec fallback
            logger.debug("üîç Cas standard - EasyOCR pr√©f√©r√©")
            try:
                return self.easyocr.extract_text(image)
            except Exception:
                logger.warning("üîÑ EasyOCR √©chou√©, fallback vers Tesseract")
                return self.tesseract.extract_text(image)
    
    async def _combine_engines(self, image: Image.Image) -> OCRFullResult:
        """Combine les r√©sultats des deux moteurs"""
        # Ex√©cuter les deux moteurs
        tesseract_result = self.tesseract.extract_text(image)
        easyocr_result = self.easyocr.extract_text(image)
        
        # Fusion sophistiqu√©e des r√©sultats des deux moteurs
        from difflib import SequenceMatcher
        
        # Analyser les similarit√©s entre les textes extraits
        tesseract_text = tesseract_result.text.strip()
        easyocr_text = easyocr_result.text.strip()
        
        similarity = SequenceMatcher(None, tesseract_text, easyocr_text).ratio()
        
        # Si les r√©sultats sont tr√®s similaires (>80%), fusionner les mots avec les meilleures confidences
        if similarity > 0.8:
            logger.debug(f"üîç Fusion des r√©sultats (similarit√©: {similarity:.2f})")
            
            # Prendre les mots avec la meilleure confiance de chaque moteur
            fused_words = []
            tesseract_words = tesseract_result.words
            easyocr_words = easyocr_result.words
            
            # Si m√™me nombre de mots, comparer mot par mot
            if len(tesseract_words) == len(easyocr_words):
                for t_word, e_word in zip(tesseract_words, easyocr_words):
                    if t_word.confidence > e_word.confidence:
                        fused_words.append(t_word)
                    else:
                        fused_words.append(e_word)
            else:
                # Sinon, prendre le r√©sultat avec la meilleure confiance globale
                if tesseract_result.confidence_avg > easyocr_result.confidence_avg:
                    fused_words = tesseract_words
                else:
                    fused_words = easyocr_words
            
            # Cr√©er le r√©sultat fusionn√©
            fused_text = " ".join([word.text for word in fused_words])
            fused_confidence = sum([word.confidence for word in fused_words]) / len(fused_words) if fused_words else 0
            
            return OCRFullResult(
                text=fused_text,
                words=fused_words,
                confidence_avg=fused_confidence,
                processing_time=max(tesseract_result.processing_time, easyocr_result.processing_time),
                image_hash=tesseract_result.image_hash
            )
        else:
            # R√©sultats trop diff√©rents, choisir celui avec la meilleure confiance
            if tesseract_result.confidence_avg > easyocr_result.confidence_avg:
                logger.debug(f"üîç Tesseract s√©lectionn√© (confiance: {tesseract_result.confidence_avg:.2f} vs {easyocr_result.confidence_avg:.2f})")
                return tesseract_result
            else:
                logger.debug(f"üîç EasyOCR s√©lectionn√© (confiance: {easyocr_result.confidence_avg:.2f} vs {tesseract_result.confidence_avg:.2f})")
                return easyocr_result
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du moteur OCR"""
        stats = {
            "cache_size": len(self.cache.cache) if self.cache else 0,
            "tesseract_available": True,  # D√©j√† v√©rifi√© √† l'initialisation
            "easyocr_available": self.easyocr.reader is not None
        }
        return stats
    
    def save_cache(self):
        """Sauvegarde le cache OCR"""
        if self.cache:
            self.cache.save()
            logger.info("üíæ Cache OCR sauvegard√©")

# Fonctions utilitaires
async def quick_ocr(image: Image.Image, engine: str = "auto") -> str:
    """OCR rapide pour r√©cup√©rer juste le texte"""
    ocr_engine = OCREngine()
    await ocr_engine.initialize()
    
    result = await ocr_engine.extract_text(image, engine)
    return result.all_text

async def analyze_text_regions(image: Image.Image) -> List[OCRResult]:
    """Analyse d√©taill√©e des r√©gions de texte"""
    ocr_engine = OCREngine()
    await ocr_engine.initialize()
    
    result = await ocr_engine.extract_text(image, "both")
    return result.words

if __name__ == "__main__":
    async def test_ocr():
        from core.vision.screen_capture import quick_screenshot
        
        # Test avec une capture d'√©cran
        screenshot = await quick_screenshot()
        if screenshot:
            ocr_engine = OCREngine()
            await ocr_engine.initialize()
            
            result = await ocr_engine.extract_text(screenshot.image, "auto")
            
            print(f"‚úÖ Texte extrait ({result.confidence_avg:.1%} confiance):")
            print(result.all_text[:200] + "..." if len(result.all_text) > 200 else result.all_text)
            print(f"üìä {len(result.words)} mots d√©tect√©s en {result.processing_time:.2f}s")
    
    asyncio.run(test_ocr())