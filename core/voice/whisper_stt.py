"""
Module de reconnaissance vocale avec Whisper pour JARVIS
Speech-to-Text haute performance avec support multilingue
"""
import asyncio
import time
import io
import wave
from typing import Optional, Dict, Any, List, Callable
from dataclasses import dataclass
from pathlib import Path
import numpy as np
from loguru import logger

# Imports conditionnels
try:
    import whisper
    import speech_recognition as sr
    import pyaudio
    WHISPER_AVAILABLE = True
except ImportError as e:
    WHISPER_AVAILABLE = False
    logger.warning(f"Modules vocaux non disponibles: {e}")

@dataclass
class VoiceConfig:
    """Configuration pour la reconnaissance vocale"""
    model_name: str = "base"  # tiny, base, small, medium, large
    language: str = "fr"  # auto-dÃ©tection si None
    energy_threshold: int = 300
    timeout: float = 5.0
    phrase_timeout: float = 1.0
    sample_rate: int = 16000
    chunk_size: int = 1024
    channels: int = 1

@dataclass
class TranscriptionResult:
    """RÃ©sultat d'une transcription"""
    text: str
    confidence: float
    language: str
    processing_time: float
    segments: List[Dict[str, Any]]
    success: bool = True
    error: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "text": self.text,
            "confidence": self.confidence,
            "language": self.language,
            "processing_time": self.processing_time,
            "segments": self.segments,
            "success": self.success,
            "error": self.error
        }

class AudioCapture:
    """Gestionnaire de capture audio"""
    
    def __init__(self, config: VoiceConfig):
        self.config = config
        self.recognizer = None
        self.microphone = None
        self.is_listening = False
        self.audio_queue = asyncio.Queue()
        
        if WHISPER_AVAILABLE:
            self.recognizer = sr.Recognizer()
            self.recognizer.energy_threshold = config.energy_threshold
            self.recognizer.timeout = config.timeout
            self.recognizer.phrase_timeout = config.phrase_timeout
    
    async def initialize(self):
        """Initialise la capture audio"""
        if not WHISPER_AVAILABLE:
            raise RuntimeError("Modules vocaux non disponibles")
        
        try:
            # Initialiser le microphone
            self.microphone = sr.Microphone(sample_rate=self.config.sample_rate)
            
            # Calibrer le bruit ambiant
            logger.info("ğŸ¤ Calibration du microphone...")
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
            
            logger.success(f"âœ… Microphone calibrÃ© (seuil: {self.recognizer.energy_threshold})")
            
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation microphone: {e}")
            raise
    
    async def listen_once(self) -> Optional[bytes]:
        """Ã‰coute un seul Ã©noncÃ©"""
        if not self.recognizer or not self.microphone:
            return None
        
        try:
            logger.debug("ğŸ‘‚ Ã‰coute en cours...")
            
            # Ã‰couter avec timeout
            with self.microphone as source:
                audio = self.recognizer.listen(
                    source, 
                    timeout=self.config.timeout,
                    phrase_time_limit=10  # Maximum 10 secondes par phrase
                )
            
            logger.debug("ğŸµ Audio capturÃ©")
            return audio.get_wav_data()
            
        except sr.WaitTimeoutError:
            logger.debug("â±ï¸ Timeout d'Ã©coute")
            return None
        except Exception as e:
            logger.error(f"âŒ Erreur capture audio: {e}")
            return None
    
    async def start_continuous_listening(self, callback: Callable):
        """DÃ©marre l'Ã©coute continue avec callback"""
        if self.is_listening:
            logger.warning("âš ï¸ Ã‰coute dÃ©jÃ  en cours")
            return
        
        self.is_listening = True
        logger.info("ğŸ”„ DÃ©marrage de l'Ã©coute continue...")
        
        try:
            while self.is_listening:
                audio_data = await self.listen_once()
                if audio_data:
                    await callback(audio_data)
                
                # Petite pause pour Ã©viter la surcharge CPU
                await asyncio.sleep(0.1)
                
        except Exception as e:
            logger.error(f"âŒ Erreur Ã©coute continue: {e}")
        finally:
            self.is_listening = False
            logger.info("â¹ï¸ Ã‰coute continue arrÃªtÃ©e")
    
    def stop_listening(self):
        """ArrÃªte l'Ã©coute continue"""
        self.is_listening = False

class WhisperSTT:
    """Service de reconnaissance vocale Whisper"""
    
    def __init__(self, config: VoiceConfig = None):
        self.config = config or VoiceConfig()
        self.model = None
        self.audio_capture = AudioCapture(self.config)
        self.stats = {
            "transcriptions_total": 0,
            "transcriptions_success": 0,
            "total_processing_time": 0.0,
            "avg_confidence": 0.0
        }
        
        logger.info("ğŸ¤ Module Whisper STT initialisÃ©")
    
    async def initialize(self):
        """Initialise Whisper et l'audio"""
        if not WHISPER_AVAILABLE:
            logger.error("âŒ Whisper non disponible")
            return False
        
        try:
            # Charger le modÃ¨le Whisper
            logger.info(f"ğŸ”„ Chargement du modÃ¨le Whisper {self.config.model_name}...")
            self.model = whisper.load_model(self.config.model_name)
            logger.success(f"âœ… ModÃ¨le Whisper {self.config.model_name} chargÃ©")
            
            # Initialiser la capture audio
            await self.audio_capture.initialize()
            
            logger.success("âœ… Whisper STT prÃªt")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation Whisper: {e}")
            return False
    
    async def transcribe_audio_data(self, audio_data: bytes) -> TranscriptionResult:
        """Transcrit des donnÃ©es audio"""
        if not self.model:
            return TranscriptionResult(
                text="", confidence=0.0, language="", processing_time=0.0,
                segments=[], success=False, error="ModÃ¨le non initialisÃ©"
            )
        
        start_time = time.time()
        self.stats["transcriptions_total"] += 1
        
        try:
            # Convertir les donnÃ©es audio en fichier temporaire
            temp_audio_path = self._save_temp_audio(audio_data)
            
            # Transcription avec Whisper
            result = self.model.transcribe(
                str(temp_audio_path),
                language=self.config.language if self.config.language != "auto" else None,
                word_timestamps=True
            )
            
            # Nettoyer le fichier temporaire
            temp_audio_path.unlink()
            
            # Extraire les informations
            text = result["text"].strip()
            language = result["language"]
            segments = result.get("segments", [])
            
            # Calculer la confiance moyenne
            confidences = []
            for segment in segments:
                if "confidence" in segment:
                    confidences.append(segment["confidence"])
                elif "words" in segment:
                    word_confidences = [w.get("confidence", 0.5) for w in segment["words"] if "confidence" in w]
                    if word_confidences:
                        confidences.extend(word_confidences)
            
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.7
            
            processing_time = time.time() - start_time
            
            # Mettre Ã  jour les statistiques
            self.stats["transcriptions_success"] += 1
            self.stats["total_processing_time"] += processing_time
            self.stats["avg_confidence"] = (
                (self.stats["avg_confidence"] * (self.stats["transcriptions_success"] - 1) + avg_confidence) 
                / self.stats["transcriptions_success"]
            )
            
            logger.debug(f"ğŸ¤ Transcription: '{text}' ({avg_confidence:.2%} confiance)")
            
            return TranscriptionResult(
                text=text,
                confidence=avg_confidence,
                language=language,
                processing_time=processing_time,
                segments=segments,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ Erreur transcription: {e}")
            
            return TranscriptionResult(
                text="", confidence=0.0, language="", processing_time=processing_time,
                segments=[], success=False, error=str(e)
            )
    
    def _save_temp_audio(self, audio_data: bytes) -> Path:
        """Sauvegarde temporaire des donnÃ©es audio"""
        temp_dir = Path("temp")
        temp_dir.mkdir(exist_ok=True)
        
        temp_path = temp_dir / f"temp_audio_{int(time.time() * 1000)}.wav"
        
        with open(temp_path, 'wb') as f:
            f.write(audio_data)
        
        return temp_path
    
    async def listen_and_transcribe(self) -> TranscriptionResult:
        """Ã‰coute et transcrit un Ã©noncÃ©"""
        try:
            logger.info("ğŸ‘‚ En Ã©coute... Parlez maintenant")
            
            audio_data = await self.audio_capture.listen_once()
            if not audio_data:
                return TranscriptionResult(
                    text="", confidence=0.0, language="", processing_time=0.0,
                    segments=[], success=False, error="Aucun audio capturÃ©"
                )
            
            logger.info("ğŸ”„ Transcription en cours...")
            result = await self.transcribe_audio_data(audio_data)
            
            if result.success and result.text:
                logger.success(f"âœ… Transcrit: '{result.text}'")
            else:
                logger.warning("âš ï¸ Aucun texte dÃ©tectÃ©")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Erreur Ã©coute/transcription: {e}")
            return TranscriptionResult(
                text="", confidence=0.0, language="", processing_time=0.0,
                segments=[], success=False, error=str(e)
            )
    
    async def start_voice_activation(self, wake_word: str = "jarvis", 
                                   command_callback: Callable = None) -> None:
        """DÃ©marre la dÃ©tection de mot d'activation"""
        if not command_callback:
            logger.warning("âš ï¸ Aucun callback dÃ©fini pour les commandes")
            return
        
        logger.info(f"ğŸ¤ Activation vocale dÃ©marrÃ©e (mot-clÃ©: '{wake_word}')")
        
        async def audio_callback(audio_data: bytes):
            # Transcription rapide pour dÃ©tecter le mot d'activation
            result = await self.transcribe_audio_data(audio_data)
            
            if result.success and wake_word.lower() in result.text.lower():
                logger.info(f"ğŸ”¥ Mot d'activation dÃ©tectÃ©: '{wake_word}'")
                
                # Ã‰couter la commande suivante
                logger.info("ğŸ‘‚ En attente de votre commande...")
                command_result = await self.listen_and_transcribe()
                
                if command_result.success and command_result.text:
                    logger.info(f"ğŸ“ Commande reÃ§ue: '{command_result.text}'")
                    await command_callback(command_result.text, command_result)
                else:
                    logger.warning("âš ï¸ Commande non comprise")
        
        try:
            await self.audio_capture.start_continuous_listening(audio_callback)
        except KeyboardInterrupt:
            logger.info("â¹ï¸ Activation vocale arrÃªtÃ©e par l'utilisateur")
        except Exception as e:
            logger.error(f"âŒ Erreur activation vocale: {e}")
    
    def stop_voice_activation(self):
        """ArrÃªte la dÃ©tection vocale"""
        self.audio_capture.stop_listening()
        logger.info("â¹ï¸ Activation vocale arrÃªtÃ©e")
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du service"""
        stats = self.stats.copy()
        
        if stats["transcriptions_success"] > 0:
            stats["success_rate"] = stats["transcriptions_success"] / stats["transcriptions_total"]
            stats["avg_processing_time"] = stats["total_processing_time"] / stats["transcriptions_success"]
        else:
            stats["success_rate"] = 0.0
            stats["avg_processing_time"] = 0.0
        
        stats["whisper_available"] = WHISPER_AVAILABLE
        stats["model_name"] = self.config.model_name
        
        return stats
    
    def reset_stats(self):
        """Remet Ã  zÃ©ro les statistiques"""
        self.stats = {
            "transcriptions_total": 0,
            "transcriptions_success": 0,
            "total_processing_time": 0.0,
            "avg_confidence": 0.0
        }
        logger.info("ğŸ“Š Statistiques Whisper remises Ã  zÃ©ro")

# Fonctions utilitaires
async def quick_listen() -> str:
    """Ã‰coute rapide et retourne le texte"""
    stt = WhisperSTT()
    
    if not await stt.initialize():
        return ""
    
    result = await stt.listen_and_transcribe()
    return result.text if result.success else ""

async def test_microphone() -> bool:
    """Test du microphone"""
    try:
        stt = WhisperSTT()
        
        if not await stt.initialize():
            return False
        
        logger.info("ğŸ¤ Test du microphone - dites quelque chose...")
        result = await stt.listen_and_transcribe()
        
        if result.success:
            logger.success(f"âœ… Test rÃ©ussi: '{result.text}'")
            return True
        else:
            logger.error(f"âŒ Test Ã©chouÃ©: {result.error}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erreur test microphone: {e}")
        return False

if __name__ == "__main__":
    async def demo_whisper():
        stt = WhisperSTT()
        
        if not await stt.initialize():
            print("âŒ Impossible d'initialiser Whisper")
            return
        
        print("ğŸ¤ Demo Whisper STT - Parlez aprÃ¨s le signal...")
        
        # Test d'Ã©coute simple
        result = await stt.listen_and_transcribe()
        
        if result.success:
            print(f"âœ… Transcription: '{result.text}'")
            print(f"ğŸ“Š Confiance: {result.confidence:.2%}")
            print(f"ğŸŒ Langue: {result.language}")
            print(f"â±ï¸ Temps: {result.processing_time:.2f}s")
        else:
            print(f"âŒ Erreur: {result.error}")
        
        # Statistiques
        stats = stt.get_stats()
        print(f"\nğŸ“Š Statistiques:")
        print(f"- Transcriptions: {stats['transcriptions_total']}")
        print(f"- Taux de succÃ¨s: {stats['success_rate']:.1%}")
        print(f"- Temps moyen: {stats['avg_processing_time']:.2f}s")
    
    asyncio.run(demo_whisper())