"""
üéØ TTS Engine - Coqui.ai XTTS
Moteur de synth√®se vocale avec mod√®les avanc√©s
"""

import asyncio
import logging
from typing import Dict, Any, Optional, List, Union
import os
import numpy as np
import torch
from TTS.api import TTS
import soundfile as sf
import io
import time
import sys
sys.path.append('/app')
from presets.preset_manager import preset_manager

logger = logging.getLogger(__name__)

class TTSEngine:
    """
    Moteur TTS utilisant Coqui.ai XTTS
    Supporte multi-langues et clonage de voix
    """
    
    def __init__(
        self,
        model_name: str = "tts_models/multilingual/multi-dataset/xtts_v2",
        device: str = "cpu",
        enable_anti_hallucination: bool = True
    ):
        self.model_name = model_name
        self.device = device
        self.enable_anti_hallucination = enable_anti_hallucination
        
        self.tts = None
        self.voices: Dict[str, Dict[str, Any]] = {}
        self.model_loaded = False
        
        # Configuration anti-hallucination
        self.hallucination_patterns = [
            "thank you for watching",
            "please subscribe",
            "don't forget to",
            "in the next video",
            "merci d'avoir regard√©",
            "n'oubliez pas de"
        ]
        
        logger.info(f"üéØ TTS Engine initialis√©: {model_name} sur {device}")
    
    async def initialize(self):
        """Initialisation asynchrone du moteur TTS"""
        try:
            # Charger le mod√®le TTS
            await asyncio.get_event_loop().run_in_executor(
                None,
                self._load_model
            )
            
            # Charger les voix par d√©faut
            self._load_default_voices()
            
            self.model_loaded = True
            logger.info("‚úÖ Mod√®le TTS charg√© avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le TTS: {e}")
            raise
    
    def _load_model(self):
        """Charger le mod√®le TTS (op√©ration bloquante)"""
        # Accepter les conditions d'utilisation automatiquement
        os.environ["COQUI_TOS_AGREED"] = "1"
        self.tts = TTS(self.model_name, progress_bar=False).to(self.device)
        
    def _load_default_voices(self):
        """Charger les voix par d√©faut"""
        self.voices = {
            "default": {
                "name": "Voix par d√©faut",
                "language": "fr",
                "gender": "neutral",
                "description": "Voix synth√©tique fran√ßaise standard"
            },
            "french_male": {
                "name": "Homme fran√ßais",
                "language": "fr",
                "gender": "male",
                "description": "Voix masculine fran√ßaise"
            },
            "french_female": {
                "name": "Femme fran√ßaise", 
                "language": "fr",
                "gender": "female",
                "description": "Voix f√©minine fran√ßaise"
            },
            "english_male": {
                "name": "English Male",
                "language": "en",
                "gender": "male",
                "description": "Male English voice"
            },
            "english_female": {
                "name": "English Female",
                "language": "en", 
                "gender": "female",
                "description": "Female English voice"
            }
        }
    
    async def synthesize(
        self,
        text: str,
        voice_id: str = "default",
        language: str = "fr",
        speed: float = 1.0,
        pitch: float = 1.0,
        preset_name: Optional[str] = None,
        context: Optional[str] = None
    ) -> bytes:
        """
        Synth√©tiser du texte en audio
        
        Args:
            text: Texte √† synth√©tiser
            voice_id: ID de la voix √† utiliser
            language: Langue du texte
            speed: Vitesse de parole (0.5-2.0)
            pitch: Hauteur de voix (0.5-2.0)
            preset_name: Nom du preset vocal √† utiliser (Jarvis, etc.)
            context: Contexte pour am√©lioration du texte
            
        Returns:
            bytes: Audio WAV en bytes
        """
        if not self.model_loaded:
            raise RuntimeError("Mod√®le TTS non charg√©")
        
        try:
            # Am√©lioration du texte avec preset si fourni
            if preset_name:
                text = preset_manager.enhance_text_with_preset(text, preset_name, context)
                
                # Appliquer les param√®tres du preset
                preset_config = preset_manager.apply_preset_to_voice_config(
                    preset_name, 
                    {"voice_id": voice_id, "language": language, "speed": speed, "pitch": pitch}
                )
                
                # Utiliser les param√®tres du preset
                speed = preset_config.get('speed', speed)
                pitch = preset_config.get('pitch', pitch)
                language = preset_config.get('language', language)
            
            # Anti-hallucination
            if self.enable_anti_hallucination:
                text = self._remove_hallucinations(text)
            
            # Synth√®se dans un thread s√©par√©
            audio_array = await asyncio.get_event_loop().run_in_executor(
                None,
                self._synthesize_sync,
                text,
                voice_id,
                language,
                speed
            )
            
            # R√©cup√©rer les effets audio du preset
            preset_effects = None
            if preset_name:
                preset = preset_manager.get_preset(preset_name)
                if preset and hasattr(preset, 'get_audio_effects'):
                    preset_effects = preset.get_audio_effects()
            
            # Post-traitement pitch si n√©cessaire
            if pitch != 1.0:
                audio_array = self._adjust_pitch(audio_array, pitch)
            
            # Convertir en WAV bytes
            audio_bytes = self._array_to_wav_bytes(audio_array)
            
            # Retourner avec m√©tadonn√©es d'effets si preset utilis√©
            if preset_effects:
                return (audio_bytes, preset_effects)
            
            return audio_bytes
            
        except Exception as e:
            logger.error(f"‚ùå Erreur synth√®se TTS: {e}")
            raise
    
    def _synthesize_sync(
        self,
        text: str,
        voice_id: str,
        language: str,
        speed: float
    ) -> np.ndarray:
        """Synth√®se synchrone (pour thread executor)"""
        # Param√®tres selon la voix
        voice_config = self.voices.get(voice_id, self.voices["default"])
        
        # Synth√©tiser avec Coqui
        wav = self.tts.tts(
            text=text,
            language=language,
            speed=speed
        )
        
        # Convertir en numpy array
        if isinstance(wav, torch.Tensor):
            wav = wav.cpu().numpy()
        elif isinstance(wav, list):
            wav = np.array(wav)
            
        return wav
    
    def _remove_hallucinations(self, text: str) -> str:
        """Retirer les patterns d'hallucination connus"""
        clean_text = text
        
        for pattern in self.hallucination_patterns:
            if pattern.lower() in clean_text.lower():
                logger.warning(f"‚ö†Ô∏è Pattern d'hallucination d√©tect√©: {pattern}")
                clean_text = clean_text.replace(pattern, "")
                clean_text = clean_text.replace(pattern.lower(), "")
                clean_text = clean_text.replace(pattern.upper(), "")
        
        return clean_text.strip()
    
    def _adjust_pitch(self, audio: np.ndarray, pitch_factor: float) -> np.ndarray:
        """Ajuster la hauteur de voix"""
        # Utiliser librosa pour le pitch shifting
        import librosa
        
        # Shift pitch
        shifted = librosa.effects.pitch_shift(
            audio,
            sr=self.tts.synthesizer.output_sample_rate,
            n_steps=int((pitch_factor - 1.0) * 12)  # Convertir en demi-tons
        )
        
        return shifted
    
    def _array_to_wav_bytes(self, audio_array: np.ndarray) -> bytes:
        """Convertir array numpy en bytes WAV"""
        buffer = io.BytesIO()
        
        # Normaliser l'audio
        if np.max(np.abs(audio_array)) > 0:
            audio_array = audio_array / np.max(np.abs(audio_array))
        
        # √âcrire en WAV
        sf.write(
            buffer,
            audio_array,
            self.tts.synthesizer.output_sample_rate,
            format='WAV',
            subtype='PCM_16'
        )
        
        buffer.seek(0)
        return buffer.read()
    
    async def list_voices(self) -> List[Dict[str, Any]]:
        """Lister toutes les voix disponibles"""
        return [
            {
                "id": voice_id,
                **voice_data
            }
            for voice_id, voice_data in self.voices.items()
        ]
    
    async def clone_voice(
        self,
        name: str,
        audio_data: bytes,
        description: str = ""
    ) -> str:
        """
        Cloner une voix √† partir d'un √©chantillon audio
        
        Args:
            name: Nom de la nouvelle voix
            audio_data: Donn√©es audio de r√©f√©rence
            description: Description de la voix
            
        Returns:
            str: ID de la nouvelle voix
        """
        try:
            # G√©n√©rer ID unique
            voice_id = f"cloned_{name.lower().replace(' ', '_')}_{int(time.time())}"
            
            # Sauvegarder l'audio de r√©f√©rence
            ref_path = f"/app/models/voices/{voice_id}.wav"
            os.makedirs(os.path.dirname(ref_path), exist_ok=True)
            
            with open(ref_path, 'wb') as f:
                f.write(audio_data)
            
            # Enregistrer la voix
            self.voices[voice_id] = {
                "name": name,
                "language": "multilingual",
                "gender": "unknown",
                "description": description,
                "reference_audio": ref_path,
                "cloned": True
            }
            
            logger.info(f"‚úÖ Voix clon√©e: {voice_id}")
            return voice_id
            
        except Exception as e:
            logger.error(f"‚ùå Erreur clonage voix: {e}")
            raise
    
    def is_model_loaded(self) -> bool:
        """V√©rifier si le mod√®le est charg√©"""
        return self.model_loaded
    
    async def shutdown(self):
        """Arr√™t propre du moteur"""
        logger.info("üõë Arr√™t TTS Engine...")
        
        # Lib√©rer la m√©moire GPU si utilis√©e
        if self.tts and self.device != "cpu":
            torch.cuda.empty_cache()
        
        self.model_loaded = False
        logger.info("‚úÖ TTS Engine arr√™t√©")