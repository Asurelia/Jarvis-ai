#!/bin/bash

# ðŸš€ Script de lancement des tests JARVIS
# Usage: ./run-tests.sh [type] [options]

set -e

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"
COMPOSE_FILE="$PROJECT_DIR/docker-compose.test.yml"

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

# Fonctions utilitaires
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_header() { echo -e "${PURPLE}[JARVIS]${NC} $1"; }

# Fonction d'aide
show_help() {
    cat << EOF
ðŸ§ª Script de lancement des tests JARVIS

Usage: $0 [TYPE] [OPTIONS]

TYPES DE TESTS:
  unit              Tests unitaires uniquement
  integration       Tests d'intÃ©gration des services
  ui                Tests de l'interface utilisateur
  e2e               Tests end-to-end complets
  performance       Tests de performance et charge
  security          Tests de sÃ©curitÃ©
  all               Tous les tests (par dÃ©faut)

OPTIONS:
  --build           Reconstruire les images Docker
  --clean           Nettoyer les volumes avant les tests
  --verbose         Mode verbose pour les logs
  --parallel        Lancer les tests en parallÃ¨le
  --coverage        GÃ©nÃ©rer un rapport de couverture
  --report          GÃ©nÃ©rer un rapport HTML
  --no-cache        Ne pas utiliser le cache Docker
  --help            Afficher cette aide

EXEMPLES:
  $0 unit --verbose
  $0 integration --build --clean
  $0 e2e --coverage --report
  $0 performance --parallel
  $0 all --build --clean --verbose

PROFILS DOCKER COMPOSE:
  - unit-tests: Services minimaux pour tests unitaires
  - integration-tests: Services pour tests d'intÃ©gration
  - full-tests: Tous les services pour tests E2E
  - perf-tests: Services pour tests de performance
  - security-tests: Services pour tests de sÃ©curitÃ©

EOF
}

# VÃ©rifier les prÃ©requis
check_prerequisites() {
    log_info "VÃ©rification des prÃ©requis..."
    
    if ! command -v docker &> /dev/null; then
        log_error "Docker n'est pas installÃ©"
        exit 1
    fi
    
    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
        log_error "Docker Compose n'est pas installÃ©"
        exit 1
    fi
    
    if [ ! -f "$COMPOSE_FILE" ]; then
        log_error "Fichier docker-compose.test.yml non trouvÃ©: $COMPOSE_FILE"
        exit 1
    fi
    
    log_success "PrÃ©requis OK"
}

# Nettoyer l'environnement
cleanup_environment() {
    log_info "Nettoyage de l'environnement de test..."
    
    # ArrÃªter et supprimer les conteneurs de test
    docker-compose -f "$COMPOSE_FILE" down --volumes --remove-orphans 2>/dev/null || true
    
    # Supprimer les images si demandÃ©
    if [ "$CLEAN" = true ]; then
        log_info "Suppression des volumes et images de test..."
        docker-compose -f "$COMPOSE_FILE" down --volumes --rmi all 2>/dev/null || true
        docker system prune -f --volumes 2>/dev/null || true
    fi
    
    # CrÃ©er les rÃ©pertoires de rÃ©sultats
    mkdir -p "$PROJECT_DIR/tests/results"
    mkdir -p "$PROJECT_DIR/coverage"
    
    log_success "Environnement nettoyÃ©"
}

# Construire les images
build_images() {
    log_info "Construction des images Docker..."
    
    local build_args=""
    if [ "$NO_CACHE" = true ]; then
        build_args="--no-cache"
    fi
    
    if [ "$VERBOSE" = true ]; then
        build_args="$build_args --progress=plain"
    fi
    
    docker-compose -f "$COMPOSE_FILE" build $build_args
    
    log_success "Images construites"
}

# Lancer les tests unitaires
run_unit_tests() {
    log_header "ðŸ§ª Lancement des tests unitaires"
    
    local services="test-runner test-memory-db test-redis"
    local cmd="python -m pytest tests/test_new_components.py -v"
    
    if [ "$COVERAGE" = true ]; then
        cmd="$cmd --cov=core --cov=services --cov-report=html:/app/coverage"
    fi
    
    docker-compose -f "$COMPOSE_FILE" run --rm test-runner $cmd
}

# Lancer les tests d'intÃ©gration
run_integration_tests() {
    log_header "ðŸ”— Lancement des tests d'intÃ©gration"
    
    # DÃ©marrer les services nÃ©cessaires
    docker-compose -f "$COMPOSE_FILE" up -d brain-api-test test-memory-db test-redis
    
    # Attendre que les services soient prÃªts
    log_info "Attente des services..."
    sleep 10
    
    # Lancer les tests
    local cmd="python -m pytest tests/ -k 'integration' -v"
    if [ "$COVERAGE" = true ]; then
        cmd="$cmd --cov=core --cov=services"
    fi
    
    docker-compose -f "$COMPOSE_FILE" run --rm test-runner $cmd
}

# Lancer les tests UI
run_ui_tests() {
    log_header "ðŸŽ¨ Lancement des tests UI"
    
    # DÃ©marrer l'interface
    docker-compose -f "$COMPOSE_FILE" up -d ui-test brain-api-test test-memory-db test-redis
    
    # Attendre que l'UI soit prÃªte
    log_info "Attente de l'interface utilisateur..."
    sleep 15
    
    # Lancer les tests UI
    docker-compose -f "$COMPOSE_FILE" run --rm test-runner bash -c "
        cd ui && npm test -- --coverage --watchAll=false
    "
    
    # Tests JavaScript
    docker-compose -f "$COMPOSE_FILE" run --rm test-runner bash -c "
        cd ui && npm run test:integration
    "
}

# Lancer les tests E2E
run_e2e_tests() {
    log_header "ðŸŽ¯ Lancement des tests E2E"
    
    # DÃ©marrer tous les services
    docker-compose -f "$COMPOSE_FILE" --profile full-tests up -d
    
    # Attendre que tous les services soient prÃªts
    log_info "Attente de tous les services..."
    sleep 30
    
    # VÃ©rifier la santÃ© des services
    log_info "VÃ©rification de la santÃ© des services..."
    docker-compose -f "$COMPOSE_FILE" ps
    
    # Lancer les tests E2E
    docker-compose -f "$COMPOSE_FILE" run --rm e2e-test
}

# Lancer les tests de performance
run_performance_tests() {
    log_header "âš¡ Lancement des tests de performance"
    
    # DÃ©marrer les services pour les tests de perf
    docker-compose -f "$COMPOSE_FILE" --profile perf-tests up -d
    
    # Attendre les services
    sleep 20
    
    # Tests de charge avec K6
    docker-compose -f "$COMPOSE_FILE" run --rm performance-test
    
    # Tests de performance Python
    docker-compose -f "$COMPOSE_FILE" run --rm test-runner bash -c "
        python -m pytest tests/test_performance.py -v --benchmark-only
    "
}

# Lancer les tests de sÃ©curitÃ©
run_security_tests() {
    log_header "ðŸ”’ Lancement des tests de sÃ©curitÃ©"
    
    # DÃ©marrer les services pour les tests de sÃ©curitÃ©
    docker-compose -f "$COMPOSE_FILE" --profile security-tests up -d
    
    # Attendre les services
    sleep 15
    
    # Tests de sÃ©curitÃ© avec OWASP ZAP
    docker-compose -f "$COMPOSE_FILE" run --rm security-test
    
    # Tests de sÃ©curitÃ© Python
    docker-compose -f "$COMPOSE_FILE" run --rm test-runner bash -c "
        bandit -r core/ services/ -f json -o /app/tests/results/security-python.json || true
        safety check --json --output /app/tests/results/safety.json || true
    "
}

# GÃ©nÃ©rer les rapports
generate_reports() {
    if [ "$REPORT" = true ]; then
        log_info "GÃ©nÃ©ration des rapports..."
        
        # CrÃ©er un rapport HTML consolidÃ©
        docker-compose -f "$COMPOSE_FILE" run --rm test-runner bash -c "
            python tests/scripts/generate_report.py \
                --coverage /app/coverage \
                --results /app/tests/results \
                --output /app/tests/results/consolidated-report.html
        "
        
        log_success "Rapports gÃ©nÃ©rÃ©s dans tests/results/"
    fi
}

# Afficher les rÃ©sultats
show_results() {
    log_header "ðŸ“Š RÃ©sultats des tests"
    
    # Copier les rÃ©sultats vers l'hÃ´te
    if [ -d "$PROJECT_DIR/tests/results" ]; then
        docker-compose -f "$COMPOSE_FILE" run --rm test-runner bash -c "
            cp -r /app/tests/results/* /app/tests/results/ 2>/dev/null || true
            cp -r /app/coverage/* /app/coverage/ 2>/dev/null || true
        "
    fi
    
    echo ""
    echo "ðŸ“ Fichiers de rÃ©sultats disponibles:"
    find "$PROJECT_DIR/tests/results" -name "*.html" -o -name "*.json" -o -name "*.xml" 2>/dev/null | head -10 || echo "  Aucun rapport trouvÃ©"
    
    if [ -f "$PROJECT_DIR/coverage/index.html" ]; then
        echo "ðŸ“ˆ Rapport de couverture: file://$PROJECT_DIR/coverage/index.html"
    fi
    
    echo ""
}

# Fonction principale
main() {
    local test_type="${1:-all}"
    
    # Parse des arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --build) BUILD=true ;;
            --clean) CLEAN=true ;;
            --verbose) VERBOSE=true ;;
            --parallel) PARALLEL=true ;;
            --coverage) COVERAGE=true ;;
            --report) REPORT=true ;;
            --no-cache) NO_CACHE=true ;;
            --help) show_help; exit 0 ;;
            unit|integration|ui|e2e|performance|security|all) test_type="$1" ;;
            *) log_warning "Option inconnue: $1" ;;
        esac
        shift
    done
    
    # Configuration de l'environnement
    export COMPOSE_PROJECT_NAME="jarvis-test"
    
    if [ "$VERBOSE" = true ]; then
        set -x
        export DOCKER_BUILDKIT=0
    fi
    
    # VÃ©rifications
    check_prerequisites
    
    # Nettoyage si demandÃ©
    if [ "$CLEAN" = true ] || [ "$BUILD" = true ]; then
        cleanup_environment
    fi
    
    # Construction si demandÃ©e
    if [ "$BUILD" = true ]; then
        build_images
    fi
    
    log_header "ðŸš€ DÃ©marrage des tests JARVIS - Type: $test_type"
    
    # Lancer les tests selon le type
    case $test_type in
        unit)
            run_unit_tests
            ;;
        integration)
            run_integration_tests
            ;;
        ui)
            run_ui_tests
            ;;
        e2e)
            run_e2e_tests
            ;;
        performance)
            run_performance_tests
            ;;
        security)
            run_security_tests
            ;;
        all)
            run_unit_tests
            run_integration_tests
            run_ui_tests
            run_e2e_tests
            ;;
        *)
            log_error "Type de test inconnu: $test_type"
            show_help
            exit 1
            ;;
    esac
    
    # GÃ©nÃ©ration des rapports
    generate_reports
    
    # Nettoyage final
    log_info "ArrÃªt des services de test..."
    docker-compose -f "$COMPOSE_FILE" down
    
    # Affichage des rÃ©sultats
    show_results
    
    log_success "ðŸŽ‰ Tests terminÃ©s avec succÃ¨s !"
}

# Gestion des signaux
cleanup_on_exit() {
    log_info "Interruption dÃ©tectÃ©e, nettoyage..."
    docker-compose -f "$COMPOSE_FILE" down 2>/dev/null || true
    exit 0
}

trap cleanup_on_exit SIGINT SIGTERM

# Point d'entrÃ©e
main "$@"