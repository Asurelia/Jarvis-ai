"""
Syst√®me de m√©moire persistante pour JARVIS avec ChromaDB
Stockage vectoriel pour conversations, patterns et pr√©f√©rences utilisateur
"""
import asyncio
import time
import json
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from pathlib import Path
import uuid
from loguru import logger

# Imports conditionnels
try:
    import chromadb
    from chromadb.config import Settings
    from sentence_transformers import SentenceTransformer
    MEMORY_AVAILABLE = True
except ImportError as e:
    MEMORY_AVAILABLE = False
    logger.warning(f"Modules de m√©moire non disponibles: {e}")

@dataclass
class MemoryEntry:
    """Entr√©e de m√©moire"""
    id: str
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[List[float]] = None
    timestamp: float = field(default_factory=time.time)
    tags: List[str] = field(default_factory=list)
    importance: float = 0.5  # 0.0 = peu important, 1.0 = tr√®s important
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "content": self.content,
            "metadata": self.metadata,
            "timestamp": self.timestamp,
            "tags": self.tags,
            "importance": self.importance
        }

@dataclass
class ConversationMemory:
    """M√©moire d'une conversation"""
    conversation_id: str
    messages: List[Dict[str, str]]
    context: Dict[str, Any]
    start_time: float
    end_time: Optional[float] = None
    summary: Optional[str] = None
    
    def add_message(self, role: str, content: str, metadata: Dict[str, Any] = None):
        """Ajoute un message √† la conversation"""
        message = {
            "role": role,
            "content": content,
            "timestamp": time.time(),
            "metadata": metadata or {}
        }
        self.messages.append(message)
    
    def get_duration(self) -> float:
        """Retourne la dur√©e de la conversation"""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

@dataclass
class UserPreference:
    """Pr√©f√©rence utilisateur"""
    key: str
    value: Any
    category: str
    confidence: float = 1.0
    learned_from: str = "explicit"  # explicit, implicit, inferred
    last_updated: float = field(default_factory=time.time)

class EmbeddingGenerator:
    """G√©n√©rateur d'embeddings pour la recherche s√©mantique"""
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model_name = model_name
        self.model = None
        self.dimension = 384  # Dimension du mod√®le MiniLM
        
    async def initialize(self):
        """Initialise le mod√®le d'embeddings"""
        if not MEMORY_AVAILABLE:
            return False
        
        try:
            logger.info(f"üîÑ Chargement du mod√®le d'embeddings {self.model_name}...")
            self.model = SentenceTransformer(self.model_name)
            logger.success(f"‚úÖ Mod√®le d'embeddings pr√™t (dimension: {self.dimension})")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le embeddings: {e}")
            return False
    
    def generate_embedding(self, text: str) -> List[float]:
        """G√©n√®re un embedding pour un texte"""
        if not self.model:
            raise RuntimeError("Mod√®le d'embeddings non disponible. Installez sentence-transformers.")
        
        try:
            embedding = self.model.encode(text, convert_to_tensor=False)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration embedding: {e}")
            raise RuntimeError(f"Impossible de g√©n√©rer l'embedding: {e}")
    
    def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """G√©n√®re des embeddings pour une liste de textes"""
        if not self.model:
            raise RuntimeError("Mod√®le d'embeddings non disponible. Installez sentence-transformers.")
        
        try:
            embeddings = self.model.encode(texts, convert_to_tensor=False)
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration embeddings batch: {e}")
            raise RuntimeError(f"Impossible de g√©n√©rer les embeddings: {e}")

class ChromaMemoryStore:
    """Store de m√©moire bas√© sur ChromaDB"""
    
    def __init__(self, persist_directory: str = "memory"):
        self.persist_directory = Path(persist_directory)
        self.client = None
        self.collections = {}
        
        # Collections pr√©d√©finies
        self.collection_names = {
            "conversations": "jarvis_conversations",
            "commands": "jarvis_commands", 
            "preferences": "jarvis_preferences",
            "patterns": "jarvis_patterns",
            "knowledge": "jarvis_knowledge"
        }
        
        logger.info(f"üíæ Store m√©moire ChromaDB initialis√© ({persist_directory})")
    
    async def initialize(self):
        """Initialise ChromaDB"""
        if not MEMORY_AVAILABLE:
            logger.error("‚ùå ChromaDB non disponible")
            return False
        
        try:
            # Cr√©er le dossier de persistance
            self.persist_directory.mkdir(exist_ok=True)
            
            # Configurer ChromaDB
            settings = Settings(
                persist_directory=str(self.persist_directory),
                anonymized_telemetry=False
            )
            
            self.client = chromadb.PersistentClient(
                path=str(self.persist_directory),
                settings=settings
            )
            
            # Cr√©er/r√©cup√©rer les collections
            for category, collection_name in self.collection_names.items():
                try:
                    collection = self.client.get_or_create_collection(
                        name=collection_name,
                        metadata={"category": category}
                    )
                    self.collections[category] = collection
                    logger.debug(f"üìö Collection '{category}' pr√™te")
                except Exception as e:
                    logger.error(f"‚ùå Erreur collection '{category}': {e}")
            
            logger.success(f"‚úÖ ChromaDB initialis√© avec {len(self.collections)} collections")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation ChromaDB: {e}")
            return False
    
    def store_memory(self, category: str, entry: MemoryEntry):
        """Stocke une entr√©e de m√©moire"""
        if category not in self.collections:
            logger.warning(f"‚ö†Ô∏è Cat√©gorie '{category}' non trouv√©e")
            return False
        
        try:
            collection = self.collections[category]
            
            # Pr√©parer les donn√©es
            documents = [entry.content]
            metadatas = [entry.metadata]
            ids = [entry.id]
            
            if entry.embedding:
                embeddings = [entry.embedding]
                collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids,
                    embeddings=embeddings
                )
            else:
                collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
            
            logger.debug(f"üíæ M√©moire stock√©e: {category}/{entry.id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur stockage m√©moire: {e}")
            return False
    
    def search_memories(self, category: str, query: str, 
                       n_results: int = 5, 
                       where: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Recherche des m√©moires par similarit√© s√©mantique"""
        if category not in self.collections:
            return []
        
        try:
            collection = self.collections[category]
            
            results = collection.query(
                query_texts=[query],
                n_results=n_results,
                where=where
            )
            
            # Formater les r√©sultats
            memories = []
            for i in range(len(results['ids'][0])):
                memory = {
                    "id": results['ids'][0][i],
                    "content": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i],
                    "distance": results['distances'][0][i] if 'distances' in results else None
                }
                memories.append(memory)
            
            return memories
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche m√©moires: {e}")
            return []
    
    def get_memory(self, category: str, memory_id: str) -> Optional[Dict[str, Any]]:
        """R√©cup√®re une m√©moire sp√©cifique par ID"""
        if category not in self.collections:
            return None
        
        try:
            collection = self.collections[category]
            
            results = collection.get(ids=[memory_id])
            
            if results['ids']:
                return {
                    "id": results['ids'][0],
                    "content": results['documents'][0],
                    "metadata": results['metadatas'][0]
                }
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration m√©moire: {e}")
            return None
    
    def update_memory(self, category: str, memory_id: str, 
                     content: str = None, metadata: Dict[str, Any] = None):
        """Met √† jour une m√©moire existante"""
        if category not in self.collections:
            return False
        
        try:
            collection = self.collections[category]
            
            update_data = {"ids": [memory_id]}
            
            if content:
                update_data["documents"] = [content]
            
            if metadata:
                update_data["metadatas"] = [metadata]
            
            collection.update(**update_data)
            
            logger.debug(f"üîÑ M√©moire mise √† jour: {category}/{memory_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour m√©moire: {e}")
            return False
    
    def delete_memory(self, category: str, memory_id: str):
        """Supprime une m√©moire"""
        if category not in self.collections:
            return False
        
        try:
            collection = self.collections[category]
            collection.delete(ids=[memory_id])
            
            logger.debug(f"üóëÔ∏è M√©moire supprim√©e: {category}/{memory_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur suppression m√©moire: {e}")
            return False
    
    def get_collection_stats(self, category: str) -> Dict[str, Any]:
        """Retourne les statistiques d'une collection"""
        if category not in self.collections:
            return {}
        
        try:
            collection = self.collections[category]
            count = collection.count()
            
            return {
                "category": category,
                "count": count,
                "name": self.collection_names[category]
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur stats collection: {e}")
            return {}

class MemorySystem:
    """Syst√®me de m√©moire principal pour JARVIS"""
    
    def __init__(self, persist_directory: str = "memory"):
        self.embedding_generator = EmbeddingGenerator()
        self.memory_store = ChromaMemoryStore(persist_directory)
        
        # Conversations actives
        self.active_conversations: Dict[str, ConversationMemory] = {}
        
        # Pr√©f√©rences utilisateur
        self.user_preferences: Dict[str, UserPreference] = {}
        
        # Cache des m√©moires fr√©quemment acc√©d√©es
        self.memory_cache = {}
        
        # Service Ollama pour les r√©sum√©s
        self.ollama_service = None
        
        # Statistiques
        self.stats = {
            "memories_stored": 0,
            "memories_retrieved": 0,
            "conversations_tracked": 0,
            "preferences_learned": 0
        }
        
        logger.info("üß† Syst√®me de m√©moire JARVIS initialis√©")
    
    async def initialize(self):
        """Initialise le syst√®me de m√©moire"""
        try:
            logger.info("üöÄ Initialisation du syst√®me de m√©moire...")
            
            # Initialiser les composants
            if not await self.embedding_generator.initialize():
                logger.warning("‚ö†Ô∏è Mod√®le d'embeddings non disponible")
            
            if not await self.memory_store.initialize():
                logger.error("‚ùå Store de m√©moire non disponible")
                return False
            
            # Charger les pr√©f√©rences utilisateur
            await self._load_user_preferences()
            
            logger.success("‚úÖ Syst√®me de m√©moire pr√™t")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation m√©moire: {e}")
            return False
    
    def set_ollama_service(self, ollama_service):
        """Configure le service Ollama pour la g√©n√©ration de r√©sum√©s"""
        self.ollama_service = ollama_service
        logger.info("ü§ñ Service Ollama configur√© pour le syst√®me de m√©moire")
    
    # === Gestion des conversations ===
    
    def start_conversation(self, context: Dict[str, Any] = None) -> str:
        """D√©marre une nouvelle conversation"""
        conversation_id = str(uuid.uuid4())
        
        conversation = ConversationMemory(
            conversation_id=conversation_id,
            messages=[],
            context=context or {},
            start_time=time.time()
        )
        
        self.active_conversations[conversation_id] = conversation
        self.stats["conversations_tracked"] += 1
        
        logger.debug(f"üí¨ Nouvelle conversation: {conversation_id}")
        return conversation_id
    
    def add_message_to_conversation(self, conversation_id: str, 
                                  role: str, content: str, 
                                  metadata: Dict[str, Any] = None):
        """Ajoute un message √† une conversation"""
        if conversation_id in self.active_conversations:
            conversation = self.active_conversations[conversation_id]
            conversation.add_message(role, content, metadata)
            logger.debug(f"üí¨ Message ajout√© √† {conversation_id}: {role}")
    
    async def end_conversation(self, conversation_id: str, 
                             save_to_memory: bool = True) -> Optional[str]:
        """Termine une conversation et la sauvegarde"""
        if conversation_id not in self.active_conversations:
            return None
        
        conversation = self.active_conversations[conversation_id]
        conversation.end_time = time.time()
        
        summary = None
        
        if save_to_memory and conversation.messages:
            # G√©n√©rer un r√©sum√© de la conversation
            summary = await self._generate_conversation_summary(conversation)
            
            # Cr√©er l'entr√©e de m√©moire
            memory_entry = MemoryEntry(
                id=conversation_id,
                content=summary,
                metadata={
                    "type": "conversation",
                    "message_count": len(conversation.messages),
                    "duration": conversation.get_duration(),
                    "context": conversation.context,
                    "start_time": conversation.start_time,
                    "end_time": conversation.end_time
                },
                tags=["conversation"],
                importance=self._calculate_conversation_importance(conversation)
            )
            
            # G√©n√©rer l'embedding
            memory_entry.embedding = self.embedding_generator.generate_embedding(summary)
            
            # Stocker en m√©moire
            self.memory_store.store_memory("conversations", memory_entry)
            self.stats["memories_stored"] += 1
        
        # Nettoyer la conversation active
        del self.active_conversations[conversation_id]
        
        logger.info(f"üí¨ Conversation termin√©e: {conversation_id}")
        return summary
    
    async def _generate_conversation_summary(self, conversation: ConversationMemory) -> str:
        """G√©n√®re un r√©sum√© d'une conversation"""
        # Construire le texte de la conversation
        conversation_text = ""
        for message in conversation.messages:
            role = message["role"]
            content = message["content"]
            conversation_text += f"{role}: {content}\n"
        
        # Utiliser l'IA pour g√©n√©rer un vrai r√©sum√© si disponible
        if hasattr(self, 'ollama_service') and self.ollama_service:
            try:
                prompt = f"""R√©sume cette conversation en 2-3 phrases concises:

{conversation_text[:1000]}  # Limiter pour √©viter des prompts trop longs

R√©sum√©:"""
                
                # Utiliser Ollama pour g√©n√©rer le r√©sum√©
                summary = await self.ollama_service.generate_text(
                    prompt,
                    model="llama3.2:3b",
                    temperature=0.3,
                    max_tokens=100
                )
                
                if summary:
                    return summary.strip()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Impossible de g√©n√©rer un r√©sum√© IA: {e}")
        
        # Fallback : r√©sum√© basique
        summary = f"Conversation avec {len(conversation.messages)} messages. "
        
        if conversation.context:
            summary += f"Contexte: {conversation.context}. "
        
        # Extraire les mots-cl√©s principaux
        words = conversation_text.lower().split()
        word_freq = {}
        for word in words:
            if len(word) > 3:  # Ignorer les mots courts
                word_freq[word] = word_freq.get(word, 0) + 1
        
        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
        if top_words:
            keywords = [word for word, _ in top_words]
            summary += f"Mots-cl√©s: {', '.join(keywords)}."
        
        return summary
    
    def _calculate_conversation_importance(self, conversation: ConversationMemory) -> float:
        """Calcule l'importance d'une conversation"""
        importance = 0.5  # Base
        
        # Plus de messages = plus important
        message_bonus = min(0.3, len(conversation.messages) * 0.02)
        importance += message_bonus
        
        # Dur√©e de conversation
        duration_bonus = min(0.2, conversation.get_duration() / 3600)  # Bonus pour dur√©e
        importance += duration_bonus
        
        return min(1.0, importance)
    
    # === Stockage de commandes et patterns ===
    
    async def store_command_execution(self, command: str, result: Dict[str, Any], 
                                    context: Dict[str, Any] = None):
        """Stocke l'ex√©cution d'une commande"""
        entry_id = hashlib.md5(f"{command}_{time.time()}".encode()).hexdigest()
        
        memory_entry = MemoryEntry(
            id=entry_id,
            content=command,
            metadata={
                "type": "command",
                "result": result,
                "context": context or {},
                "success": result.get("success", False),
                "execution_time": result.get("execution_time", 0)
            },
            tags=["command", "execution"],
            importance=0.7 if result.get("success") else 0.3
        )
        
        memory_entry.embedding = self.embedding_generator.generate_embedding(command)
        
        self.memory_store.store_memory("commands", memory_entry)
        self.stats["memories_stored"] += 1
        
        logger.debug(f"üìù Commande stock√©e: {command[:50]}...")
    
    async def store_user_pattern(self, pattern_type: str, pattern_data: Dict[str, Any]):
        """Stocke un pattern d'utilisation"""
        entry_id = hashlib.md5(f"{pattern_type}_{time.time()}".encode()).hexdigest()
        
        memory_entry = MemoryEntry(
            id=entry_id,
            content=json.dumps(pattern_data),
            metadata={
                "type": "pattern",
                "pattern_type": pattern_type,
                **pattern_data
            },
            tags=["pattern", pattern_type],
            importance=0.6
        )
        
        self.memory_store.store_memory("patterns", memory_entry)
        self.stats["memories_stored"] += 1
        
        logger.debug(f"üîÑ Pattern stock√©: {pattern_type}")
    
    # === Gestion des pr√©f√©rences ===
    
    def learn_preference(self, key: str, value: Any, category: str = "general",
                        confidence: float = 1.0, source: str = "explicit"):
        """Apprend une pr√©f√©rence utilisateur"""
        preference = UserPreference(
            key=key,
            value=value,
            category=category,
            confidence=confidence,
            learned_from=source
        )
        
        self.user_preferences[key] = preference
        self.stats["preferences_learned"] += 1
        
        logger.debug(f"üìö Pr√©f√©rence apprise: {key} = {value}")
    
    def get_preference(self, key: str, default: Any = None) -> Any:
        """R√©cup√®re une pr√©f√©rence utilisateur"""
        if key in self.user_preferences:
            return self.user_preferences[key].value
        return default
    
    async def _load_user_preferences(self):
        """Charge les pr√©f√©rences utilisateur depuis la m√©moire"""
        try:
            preferences = self.memory_store.search_memories(
                "preferences", 
                "user preferences",
                n_results=100
            )
            
            for pref_data in preferences:
                metadata = pref_data["metadata"]
                if "key" in metadata and "value" in metadata:
                    preference = UserPreference(
                        key=metadata["key"],
                        value=metadata["value"],
                        category=metadata.get("category", "general"),
                        confidence=metadata.get("confidence", 1.0),
                        learned_from=metadata.get("learned_from", "stored"),
                        last_updated=metadata.get("last_updated", time.time())
                    )
                    self.user_preferences[metadata["key"]] = preference
            
            logger.info(f"üìö {len(self.user_preferences)} pr√©f√©rences charg√©es")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement pr√©f√©rences: {e}")
    
    async def save_user_preferences(self):
        """Sauvegarde les pr√©f√©rences utilisateur"""
        try:
            for key, preference in self.user_preferences.items():
                entry_id = f"pref_{hashlib.md5(key.encode()).hexdigest()}"
                
                memory_entry = MemoryEntry(
                    id=entry_id,
                    content=f"Pr√©f√©rence utilisateur: {key} = {preference.value}",
                    metadata={
                        "type": "preference",
                        "key": key,
                        "value": preference.value,
                        "category": preference.category,
                        "confidence": preference.confidence,
                        "learned_from": preference.learned_from,
                        "last_updated": preference.last_updated
                    },
                    tags=["preference", preference.category],
                    importance=0.8
                )
                
                self.memory_store.store_memory("preferences", memory_entry)
            
            logger.info(f"üíæ {len(self.user_preferences)} pr√©f√©rences sauvegard√©es")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde pr√©f√©rences: {e}")
    
    # === Recherche et r√©cup√©ration ===
    
    async def search_memories(self, query: str, category: str = None, 
                            limit: int = 5) -> List[Dict[str, Any]]:
        """Recherche des m√©moires par similarit√© s√©mantique"""
        self.stats["memories_retrieved"] += 1
        
        if category:
            return self.memory_store.search_memories(category, query, limit)
        else:
            # Rechercher dans toutes les cat√©gories
            all_results = []
            for cat in self.memory_store.collection_names.keys():
                results = self.memory_store.search_memories(cat, query, limit)
                all_results.extend(results)
            
            # Trier par pertinence (distance)
            all_results.sort(key=lambda x: x.get("distance", 1.0))
            return all_results[:limit]
    
    async def get_relevant_context(self, query: str, max_context: int = 3) -> str:
        """R√©cup√®re le contexte pertinent pour une requ√™te"""
        memories = await self.search_memories(query, limit=max_context)
        
        context_parts = []
        for memory in memories:
            content = memory["content"]
            context_parts.append(content)
        
        return "\n".join(context_parts) if context_parts else ""
    
    # === Statistiques et maintenance ===
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du syst√®me de m√©moire"""
        stats = self.stats.copy()
        
        # Ajouter les stats des collections
        collection_stats = {}
        for category in self.memory_store.collection_names.keys():
            collection_stats[category] = self.memory_store.get_collection_stats(category)
        
        stats.update({
            "collections": collection_stats,
            "active_conversations": len(self.active_conversations),
            "user_preferences": len(self.user_preferences),
            "memory_available": MEMORY_AVAILABLE
        })
        
        return stats
    
    def clear_memory_cache(self):
        """Vide le cache m√©moire"""
        self.memory_cache.clear()
        logger.info("üóëÔ∏è Cache m√©moire vid√©")
    
    async def cleanup_old_memories(self, days_old: int = 30):
        """Nettoie les vieilles m√©moires peu importantes"""
        # TODO: Impl√©menter le nettoyage bas√© sur l'√¢ge et l'importance
        logger.info(f"üßπ Nettoyage des m√©moires > {days_old} jours")

# Fonctions utilitaires
async def test_memory_system():
    """Test du syst√®me de m√©moire"""
    try:
        memory = MemorySystem("test_memory")
        
        if not await memory.initialize():
            return False
        
        # Test de conversation
        conv_id = memory.start_conversation({"app": "test", "mode": "demo"})
        memory.add_message_to_conversation(conv_id, "user", "Bonjour JARVIS")
        memory.add_message_to_conversation(conv_id, "assistant", "Bonjour ! Comment puis-je vous aider ?")
        memory.add_message_to_conversation(conv_id, "user", "Peux-tu m'aider avec Python ?")
        memory.add_message_to_conversation(conv_id, "assistant", "Bien s√ªr ! Que voulez-vous savoir sur Python ?")
        
        summary = await memory.end_conversation(conv_id)
        logger.info(f"üìù R√©sum√© de conversation: {summary}")
        
        # Test de stockage de commande
        await memory.store_command_execution(
            "take a screenshot",
            {"success": True, "execution_time": 1.2},
            {"app": "test"}
        )
        
        # Test de pr√©f√©rences
        memory.learn_preference("preferred_voice", "fr-FR-DeniseNeural", "voice")
        memory.learn_preference("auto_complete", True, "interface")
        
        # Test de recherche
        results = await memory.search_memories("Python programmation")
        logger.info(f"üîç R√©sultats de recherche: {len(results)}")
        
        # Statistiques
        stats = memory.get_stats()
        logger.info(f"üìä Statistiques m√©moire:")
        logger.info(f"  - M√©moires stock√©es: {stats['memories_stored']}")
        logger.info(f"  - Conversations: {stats['conversations_tracked']}")
        logger.info(f"  - Pr√©f√©rences: {stats['preferences_learned']}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur test m√©moire: {e}")
        return False

if __name__ == "__main__":
    asyncio.run(test_memory_system())